{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üöÄ Principal Component Analysis (PCA) - Day 33\n",
    "\n",
    "Welcome to Day 33 of the **100 Days of Data Science & AI** series! Today, we are diving deep into **Principal Component Analysis (PCA)**, one of the most powerful and widely used techniques for dimensionality reduction and data visualization.\n",
    "\n",
    "---\n",
    "\n",
    "## üßê What is PCA?\n",
    "\n",
    "Principal Component Analysis (PCA) is an **unsupervised machine learning** algorithm used for dimensionality reduction. It transforms a large set of variables into a smaller one that still contains most of the information in the large set.\n",
    "\n",
    "### Why do we need it?\n",
    "1. **Curse of Dimensionality**: High-dimensional datasets are often hard to visualize and can lead to overfitting.\n",
    "2. **Visualization**: Reducing data to 2D or 3D allows us to see patterns that were hidden in higher dimensions.\n",
    "3. **Speed**: Training models on fewer features is faster and often more efficient.\n",
    "4. **Noise Reduction**: PCA helps in eliminating noisy features that don't contribute significantly to the variance.\n",
    "\n",
    "---\n",
    "\n",
    "## üõ†Ô∏è The Mechanics of PCA\n",
    "\n",
    "1. **Standardization**: PCA is sensitive to variances, so features must be scaled to have a mean of 0 and variance of 1.\n",
    "2. **Covariance Matrix**: We calculate how features vary from the mean with respect to each other.\n",
    "3. **Eigen-decomposition**: We compute the **Eigenvectors** (direction of variance) and **Eigenvalues** (magnitude/strength of variance).\n",
    "4. **Principal Components**: These are the new, uncorrelated variables. PC1 captures the most variance, PC2 the second most, and so on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "sns.set(style=\"whitegrid\", palette=\"muted\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìÇ Loading the Real-World Dataset\n",
    "\n",
    "We use the **Breast Cancer Wisconsin (Diagnostic)** dataset. It contains **30 features** representing characteristics of cell nuclei from breast cancer biopsies. Our goal is to reduce these 30 features into a few Principal Components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_breast_cancer()\n",
    "df = pd.DataFrame(data.data, columns=data.feature_names)\n",
    "y = data.target\n",
    "\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚öñÔ∏è Step 1: Standardization\n",
    "\n",
    "PCA is calculated based on variance. If one feature has values between 1-100 and another between 0-1, PCA will incorrectly assume the first feature is more important."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üß± Step 2: Applying PCA\n",
    "\n",
    "We will reduce the 30 dimensions into 3 for visualization, and then analyze how much information each component retains."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=3)\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "pca_df = pd.DataFrame(X_pca, columns=['PC1', 'PC2', 'PC3'])\n",
    "pca_df['Target'] = y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä Step 3: Advanced Visualizations\n",
    "\n",
    "### 1. üìâ Scree Plot (Explained Variance)\n",
    "This plot shows how much total variance (information) is captured by each principal component."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_var_pca = pca.explained_variance_ratio_\n",
    "cum_sum_eigenvalues = np.cumsum(exp_var_pca)\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.bar(range(0, len(exp_var_pca)), exp_var_pca, alpha=0.5, align='center', label='Individual explained variance')\n",
    "plt.step(range(0, len(cum_sum_eigenvalues)), cum_sum_eigenvalues, where='mid', label='Cumulative explained variance')\n",
    "plt.ylabel('Explained variance ratio')\n",
    "plt.xlabel('Principal component index')\n",
    "plt.title('Scree Plot - Captured Information')\n",
    "plt.legend(loc='best')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. üîµ 2D Projection\n",
    "Even with just two components, notice how clear the separation between malignant and benign tumors becomes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 7))\n",
    "sns.scatterplot(x='PC1', y='PC2', hue='Target', data=pca_df, palette='viridis', alpha=0.7)\n",
    "plt.title('2D PCA Projection of Breast Cancer Dataset')\n",
    "plt.xlabel(f'PC1 ({exp_var_pca[0]:.2%} Variance)')\n",
    "plt.ylabel(f'PC2 ({exp_var_pca[1]:.2%} Variance)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. üßä 3D Projection\n",
    "A 3D view captures even more nuance (over 70% of total variance in this dataset)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12, 9))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.scatter(pca_df['PC1'], pca_df['PC2'], pca_df['PC3'], c=y, cmap='viridis', alpha=0.6)\n",
    "ax.set_xlabel('PC1')\n",
    "ax.set_ylabel('PC2')\n",
    "ax.set_zlabel('PC3')\n",
    "ax.set_title('3D PCA Visualization')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. üó∫Ô∏è Feature Biplot (Heatmap of Components)\n",
    "We can see how much each original feature contributes to the first two Principal Components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "sns.heatmap(pca.components_[:2], \n",
    "            yticklabels=['PC1', 'PC2'], \n",
    "            xticklabels=data.feature_names, \n",
    "            cmap='coolwarm')\n",
    "plt.title('Feature Contribution to Principal Components')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "üîπ Key Takeaways\n",
    "\n",
    "‚úî **Dimensionality Reduction**: We successfully reduced 30 features into 2-3 components while retaining the majority of the variance (information).\n",
    "\n",
    "‚úî **Standardization is Critical**: Without scaling the breast cancer features, the PCA directions would be dominated by features with the largest raw numerical ranges.\n",
    "\n",
    "‚úî **Visualization Insights**: PCA projected the data in a way that allows us to visually differentiate between tumor types, which would be impossible in a 30-column table.\n",
    "\n",
    "üìå Meta\n",
    "Author: Tharun Naik Ramavath\n",
    "Series: 100 Days of Data Science & AI\n",
    "Day: 33\n",
    "Platform: LinkedIn\n",
    "Notebook: Google Colab"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
